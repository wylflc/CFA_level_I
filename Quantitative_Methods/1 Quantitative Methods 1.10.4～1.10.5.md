# 1 Quantitative Methods 量化方法
## 1.10 Simple Linear Regression 简单线性回归
### 1.10.4 Prediction in the Simple Linear Regression Model 简单线性回归模型中的预测
#### ANOVA 与简单线性回归中的估计标准误差

在简单线性回归中，我们可以使用方差分析（ANOVA）表来分解总变异，并计算相关统计量，以评估模型的拟合优度（goodness of fit）。其中，估计标准误差（standard error of estimate, $s_e$）是衡量观测值 $Y$ 与预测值 $\hat{Y}$ 之间平均偏差的重要指标。

##### **ANOVA 表及其组成部分**
方差分析表通常包括回归平方和（SSR）、误差平方和（SSE）和总平方和（SST），对应的自由度、均方以及 F 统计量。ANOVA 表的结构如下：

| **Source**  | **Sum of Squares** $SS$  | **Degrees of Freedom** $df$ | **Mean Square** $MS$ | **F-Statistic** |
|------------|-----------------------------|-------------------------------|-------------------------|-----------------|
| **Regression** | $SSR = \sum_{i=1}^{n} (\hat{Y}_i - \bar{Y})^2$ | $k = 1$ | $MSR = \frac{SSR}{k}$ | $F = \frac{MSR}{MSE}$ |
| **Error** | $SSE = \sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2$ | $n - k - 1$ | $MSE = \frac{SSE}{n - k - 1}$ | |
| **Total** | $SST = \sum_{i=1}^{n} (Y_i - \bar{Y})^2$ | $n - 1$ | | |

其中：
- **总平方和（SST）** 衡量因变量 $Y$ 的总变异性。
- **回归平方和（SSR）** 代表由回归模型解释的变异性。
- **误差平方和（SSE）** 代表未被回归模型解释的变异性。

##### **估计标准误差的计算**
估计标准误差（standard error of estimate, $s_e$），也称为回归标准误差（standard error of regression），用于衡量实际值 $Y$ 与预测值 $\hat{Y}$ 之间的平均偏差。它的计算公式如下：

$$s_e = \sqrt{MSE} = \sqrt{\frac{\sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2}{n - 2}}$$

其中：
- $s_e$ 越小，说明模型拟合越好，观测值更接近预测值。
- $s_e$ 的单位与因变量 $Y$ 相同，提供了回归模型误差的绝对度量。

##### **ROA 回归模型的 ANOVA 计算**
以 ROA 作为因变量，CAPEX 作为自变量的简单线性回归模型为例，其 ANOVA 计算如下：

| **Source**  | **Sum of Squares** | **Degrees of Freedom** | **Mean Square** | **F-Statistic** |
|------------|------------------|----------------------|----------------|----------------|
| **Regression** | 191.625 | 1 | 191.625 | 16.0104 |
| **Error** | 47.875 | 4 | 11.96875 | |
| **Total** | 239.50 | 5 | | |

可以计算 F 统计量：

$$F = \frac{MSR}{MSE} = \frac{191.625}{11.96875} = 16.0104$$

在 5% 的显著性水平下，F 的临界值为 7.71（可通过 Excel `F.INV(0.95,1,4)`、R `qf(.95,1,4)` 或 Python `from scipy.stats import f; f.ppf(.95,1,4)` 计算）。由于 $F = 16.0104 > 7.71$，我们拒绝原假设，说明回归模型具有统计上的显著性。

##### **结论**
- **F 统计量** 用于检验回归模型的总体显著性，如果回归平方和 $SSR$ 相较于误差平方和 $SSE$ 够大，则说明模型具有统计显著性。
- **估计标准误差 $s_e$** 反映模型拟合的绝对误差，通常用于计算预测区间和进行回归系数的假设检验。
- 统计软件（如 Excel、R、Python、SAS、SPSS 等）能够自动生成 ANOVA 表，帮助快速评估回归模型的拟合优度。

通过 ANOVA 和标准误差的计算，我们能够更好地理解线性回归模型的统计性质，并评估其适用性。

#### 使用简单线性回归进行预测及预测区间

简单线性回归不仅用于预测因变量（如销售增长），还需要评估预测结果的不确定性。预测值 $\hat{Y}_f$ 基于回归方程计算，但由于回归线仅描述了因变量与自变量之间的平均关系，预测也会有误差。

**预测公式：**

$$\hat{Y}_f = \hat{b}_0 + \hat{b}_1 X_f$$

预测结果不仅要计算预测值，还需要考虑不确定性，这通常通过预测标准误差来实现：

$$s_f = s_e \sqrt{1 + \frac{1}{n} + \frac{(X_f - \bar{X})^2}{\sum_{i=1}^n (X_i - \bar{X})^2}}$$

**影响因素：**
- **标准误差 $s_e$**：回归模型拟合的好坏决定了预测的准确性；
- **样本量 $n$**：样本量越大，预测误差越小；
- **预测值与均值的偏差**：预测的自变量越接近回归方程中自变量的均值，预测误差越小。

一旦计算了预测标准误差，可以用它来构建预测区间，公式如下：

$$\hat{Y}_f \pm t_{\text{critical}} \times s_f$$

**结论：**
- 回归模型的预测标准误差与自变量的变动、样本量及预测值的准确性密切相关；
- 预测区间反映了预测结果的不确定性，给出一个范围而非单一预测值。

### 1.10.5 Functional Forms for Simple Linear Regression 简单线性回归的函数形式

**学习目标**  
描述不同的简单线性回归函数形式

并非所有的因变量与自变量之间都具有线性关系。经济和金融数据中常常出现非线性关系。比如，公司的收入增长可能随着时间的推移而发生变化，最初的增长率为 15%，后来下降到 5%。如果用简单线性回归模型来估计这种关系，可能会低估或高估某些区间的收入。

**常见的函数形式：**
1. **对数-线性模型（Log-Lin）**：因变量取对数，自变量不变：
   $$ \ln Y_i = b_0 + b_1 X_i $$  
   该模型中，回归系数表示自变量变化时因变量的相对变化。

2. **线性-对数模型（Lin-Log）**：自变量取对数，因变量不变：
   $$ Y_i = b_0 + b_1 \ln X_i $$  
   该模型中，回归系数表示自变量相对变化对因变量的绝对影响。

3. **对数-对数模型（Log-Log）**：因变量和自变量均取对数：
   $$ \ln Y_i = b_0 + b_1 \ln X_i $$  
   该模型特别适用于计算弹性，回归系数表示因变量和自变量相对变化的关系。

**实例：**

- **对数-线性模型**：在收入和时间的回归中，将收入取对数后拟合回归模型，结果比简单线性回归模型更好。

- **线性-对数模型**：在营业利润率与单位销售额之间的回归中，使用单位销售额的对数转化后，模型的拟合度大大提高。

- **对数-对数模型**：在广告支出和收入的回归中，采用对数转化后的模型，拟合度显著提高。

**选择合适的函数形式**  
选择适当的回归模型需要依靠拟合优度指标（$R^2$，F统计量和估计的标准误差）以及残差分析。残差图有助于判断模型是否合适，理想情况下，残差应该是随机的。

**结论**  
在回归分析中，通过适当的变量转化，尤其是对数转化，可以改善模型的拟合度，使得非线性关系能够在简单线性回归模型中得到更好的处理。