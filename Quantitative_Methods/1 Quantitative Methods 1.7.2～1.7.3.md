# 1 Quantitative Methods 量化方法
## 1.7 Estimation and Inference 估计与推断
### 1.7.2 Central Limit Theorem and Inference 中心极限定理与推断

#### 1. 定义

中心极限定理（Central Limit Theorem, CLT）是统计学中的一个重要定理，它指出：**当样本量足够大时**，无论原始总体分布的形状如何，样本均值的分布将会近似于正态分布。

具体来说，如果我们从任何具有均值 $\mu$ 和标准差 $\sigma$ 的总体中抽取独立的随机样本，样本均值 $\overline{X}$ 的分布将会趋近于正态分布，且其性质如下：
$$
\overline{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)
$$
其中：
- $\mu$ 是总体的均值，
- $\sigma$ 是总体的标准差，
- $n$ 是样本的大小。

#### 2. 重要性质

- **样本均值的分布**：随着样本大小 $n$ 增加，样本均值的分布逐渐接近正态分布，即使总体分布并非正态分布。
- **均值**：样本均值的分布的均值将等于抽样总体的均值。
- **标准误差**：样本均值的标准误差是 $\frac{\sigma}{\sqrt{n}}$，它表示样本均值的分布的标准偏差。

**标准差与标准误差的区别**

简而言之，**标准差**衡量的是数据相对于均值的**分散程度**，而**标准误差**衡量的是从样本数据中估计总体参数时的**准确性**。标准差和标准误差之间的对比反映了数据描述与推断之间的区别。
- 如果我们想了解数据的分布有多广，使用标准差。
- 如果我们想了解从样本数据估计的总体参数与其真实值之间的精确度，使用标准误差。

### 1.7.3 Bootstrapping and Empirical Sampling Distributions 自助法与经验采样分布

自助法（Bootstrapping）是一种通过对原始样本进行重复抽样来估计总体分布的方法。它是非参数的统计技术，允许通过从样本数据中生成新的样本，来估算统计量的标准误差、置信区间等。这种方法不需要对总体分布作出假设，因此非常适合于复杂或不明确定义的分布。

#### 自助法的步骤：
1. 从原始样本中进行有放回的随机抽样，生成新的样本集（即自助样本）。
2. 对自助样本计算所需的统计量（如均值、中位数、标准差等）。
3. 重复步骤1和步骤2多次，通常进行成千上万次，以生成一个统计量的分布。
4. 基于这个分布，可以估算统计量的标准误差、置信区间等。

#### 经验采样分布（Empirical Sampling Distribution）
经验采样分布是通过从实际数据中多次重复抽样获得的统计量分布。与理论上的采样分布不同，经验采样分布依赖于实际数据而非总体假设，因此更为灵活。自助法生成的统计量分布就是经验采样分布的一种形式。

##### 自助法与经验采样分布的联系：
- **非参数估计**：两者都不依赖于特定的分布假设，可以用于从复杂数据中估算统计量的分布。
- **自助法是生成经验采样分布的工具**：通过自助法，我们可以基于原始数据生成经验采样分布，从而做出推断。

#### 自助法的应用：
- 估计统计量的标准误差。
- 构建置信区间。
- 在不明确知道总体分布的情况下进行假设检验。

总体来说，自助法和经验采样分布为复杂或未知分布的数据提供了强大的工具，能够帮助我们在不依赖传统假设的情况下进行统计推断。

#### Jackknife 删除法

删除法（Jackknife）是另一种用于统计推断总体参数的重抽样技术。与自助法（bootstrap）不同，自助法是通过有放回地重复抽取样本，而删除法则是通过每次从原始观测数据中删除一个观察值（不放回）来选取样本。删除法通常用于减少估计量的偏差，其他应用包括寻找估计量的标准误差和置信区间。

根据其计算过程，我们可以得出结论：删除法在每次运行时通常会产生相似的结果，而自助法则因为重抽样是随机抽取的，通常会产生不同的结果。对于一个大小为n的样本，删除法通常需要n次重复，而自助法则则由用户决定进行多少次重复。

删除法的一个关键优势是它能在不依赖于数据分布的假设下进行估计。虽然它产生的结果通常比自助法更加稳定，但它的缺点是无法应对某些复杂的估计量。因此，在特定情况下，删除法是一种有效的选择。


