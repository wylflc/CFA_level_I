# 1 Quantitative Methods 量化方法
## 1.10 Simple Linear Regression 简单线性回归

#### 学习要点

- **描述简单线性回归模型**，解释**最小二乘准则**如何用于估计回归系数，并理解这些系数的含义。
- **解释简单线性回归模型的假设**，并描述**残差和残差图**如何指示这些假设是否可能被违反。
- **计算并解释拟合优度的度量**，以及**构建和评估拟合检验和回归系数的检验**。
- **描述方差分析（ANOVA）在回归分析中的应用**，解释 ANOVA 结果，并**计算和解释简单线性回归中的估计标准误**。
- **计算并解释因变量的预测值**，以及在给定估计的线性回归模型和自变量值的情况下，**计算并解释其预测区间**。
- **描述简单线性回归的不同函数形式**。

### 1.10.1 Estimation of the Simple Linear Regression Model 简单线性回归模型的估计

线性回归是一种用于建模因变量（响应变量）与一个或多个自变量（预测变量）之间关系的统计方法。回归分析的核心目标是找到最能解释变量间关系的数学表达式，并用于预测或推断。

#### 简单线性回归参数估计

##### 1. 关键概念
- **因变量（Y）**：希望解释其变化的变量。
- **自变量（X）**：用于解释因变量变化的变量。
- **最小二乘法（OLS）**：回归分析的核心方法，通过最小化残差平方和找到最佳拟合直线。

##### 2. 线性回归模型
数学表达式：
$$
Y_i = b_0 + b_1 X_i + \epsilon_i, \quad i = 1, \dots, n
$$
其中：
- $b_0$（截距）：$X = 0$ 时的 $Y$ 值。
- $b_1$（斜率）：$X$ 每增加一个单位，$Y$ 的期望变化量。
- $\epsilon_i$（误差项）：$Y$ 的实际值与预测值之间的偏差。

##### 3. 线性回归的目标
- 通过**最小二乘法**估计 $b_0$ 和 $b_1$，找到最优回归线。
- 拟合的回归线代表 $X$ 和 $Y$ 之间的**平均关系**，并不要求所有数据点落在回归线上。

#### 估计回归线

##### 估计回归模型的参数

在回归模型中，我们无法直接观察总体参数 $b_0$ 和 $b_1$，只能通过样本估计 $\hat{b}_0$ 和 $\hat{b}_1$，其中“帽子”表示这些参数是估计值。因此，预测和检验均基于样本估计值，而非未知的总体参数。

##### 最小二乘法与残差

我们估计的回归线是最符合观测数据的直线。在简单线性回归中，估计的截距 $\hat{b}_0$ 和斜率 $\hat{b}_1$ 使得观测值与拟合直线之间的垂直距离平方和最小。即最小化 $\sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2$，其中：

- $\hat{Y}_i = \hat{b}_0 + \hat{b}_1 X_i$ 是回归线上的预测值；
- $e_i = Y_i - \hat{Y}_i$ 是第 $i$ 个观测值的残差。

需要注意，误差项与残差的区别：
- 误差项指总体中的真实关系，而
- 残差指基于样本拟合的回归关系。

##### 误差平方和（SSE）

回归线的拟合要求最小化残差平方和（即误差平方和，SSE）：
$$
SSE = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} \left[Y_i - (\hat{b}_0 + \hat{b}_1 X_i)\right]^2
$$

##### 斜率与截距的计算

斜率 $\hat{b}_1$ 计算如下：

$$
\hat{b}_1 = \frac{\sum_{i=1}^{n} (Y_i - \bar{Y}) (X_i - \bar{X})}{\sum_{i=1}^{n} (X_i - \bar{X})^2}
$$

截距 $\hat{b}_0$ 计算如下：

$$
\hat{b}_0 = \bar{Y} - \hat{b}_1 \bar{X}
$$

##### 斜率与相关系数的关系

样本相关系数 $r$ 计算如下：
$$
r = \frac{\text{Cov}(Y, X)}{S_Y S_X}
$$

其中：
- $S_Y = \sqrt{\frac{\sum_{i=1}^{n} (Y_i - \bar{Y})^2}{n-1}}$ 为 $Y$ 的标准差
- $S_X = \sqrt{\frac{\sum_{i=1}^{n} (X_i - \bar{X})^2}{n-1}}$ 为 $X$ 的标准差
- $\text{Cov}(Y, X) = \frac{\sum_{i=1}^{n} (Y_i - \bar{Y}) (X_i - \bar{X})}{n-1}$ 为协方差

##### 斜率与相关系数的符号

由于斜率和相关系数的分母始终为正，其符号取决于协方差的符号：
- 若 $\text{Cov}(Y, X) > 0$，则 $\hat{b}_1 > 0$，$r > 0$，表示正相关；
- 若 $\text{Cov}(Y, X) < 0$，则 $\hat{b}_1 < 0$，$r < 0$，表示负相关。

#### 解释回归系数

##### 截距的含义

回归模型的截距表示当自变量取零时，因变量的预测值。然而，在某些情况下，这一解释并不合理。例如：
- 若模型用于解释货币供应对 GDP 增长的影响，则截距无实际意义，因为零货币供应是不可能的；
- 但若自变量是货币供应增长率，则截距有实际意义。

##### 斜率的含义

斜率表示自变量每增加 1 个单位，因变量的变化量：
- **正斜率**：自变量和因变量变化方向相同；
- **负斜率**：自变量和因变量变化方向相反。

##### 预测值与残差的性质

利用估计的回归系数，我们可以预测因变量的值，即：
$$
\hat{Y}_i = \hat{b}_0 + \hat{b}_1 X_i
$$

最小二乘法的数学性质之一是 **残差项的期望为零**：
$$
E(\varepsilon) = 0
$$

残差性质：
- $Y_i$ 和 $\hat{Y}_i$ 的总和和均值相同；
- **残差的总和必然等于零**，但回归拟合的重点是 **最小化残差平方和**。

#### 横截面回归 vs. 时间序列回归

回归分析主要使用两种数据类型：**横截面数据**和**时间序列数据**。

##### 横截面回归 (Cross-Sectional Regression)

横截面回归使用 **同一时间段** 内多个 $X$ 和 $Y$ 观测值。观测值可能来自不同公司、资产类别、投资基金、国家或其他实体。例如：
- 研究 **多个公司** 的 **预测每股收益 (EPS) 增长** 是否能解释市盈率 (P/E) 差异。

横截面数据通常用 $i = 1, 2, \dots, n$ 表示。

##### 时间序列回归 (Time-Series Regression)

时间序列回归使用 **同一实体** 在 **不同时间** 的多个观测值。例如：
- 研究 **某国** 的 **通货膨胀率** 是否决定了其 **短期利率**，数据可能是 **多年间的月度数据**。

时间序列数据通常用 $t = 1, 2, \dots, T$ 表示。但在后续部分，我们仍可能使用 $i = 1, 2, \dots, n$ 来表示时间序列数据。

### 1.10.2 Assumptions of the Simple Linear Regression Model 简单线性回归模型的假设

我们已经讨论了如何解释简单线性回归模型中的系数。现在，我们将转向该模型背后的统计假设。假设我们有 $n$ 个 $Y$ 和 $X$ 的观测值，并且我们希望估计 $Y$ 对 $X$ 的简单线性回归。为了从简单线性回归模型中得出有效结论，我们需要做出以下四个关键假设：

1. **线性 (Linearity)**: 因变量 $Y$ 与自变量 $X$ 之间的关系是线性的。

2. **同方差性 (Homoskedasticity)**: 回归残差的方差对于所有观测值是相同的。

3. **独立性 (Independence)**: 观测值对 $(Y, X)$ 是相互独立的。这意味着回归残差在不同观测值之间是不相关的。

4. **正态性 (Normality)**: 回归残差服从正态分布。

接下来，我们将详细讨论每个假设，并介绍回归结果中检查残差图的“最佳实践”，以识别潜在的假设违反。

#### 假设 1：线性关系（Linearity）

**关键假设**：回归模型假设自变量（$X$）和因变量（$Y$）之间存在线性关系。如果该关系是非线性的，线性回归模型将无法准确拟合数据，导致偏差。对于非线性关系，使用线性模型会低估或高估某些 $X$ 值的因变量。

**重要概念**：
1. **线性关系**：因变量和自变量之间的关系应为线性。若关系是非线性（例如 $Y_i = b_0 e^{b_1 X_i} + \epsilon_i$），则线性回归模型不适用。
2. **自变量非随机**：回归模型假设自变量不是随机的，否则无法建立线性关系。
3. **残差图**：当回归模型适合数据时，残差应随机分布。残差图应没有明显的模式或趋势。

**问题示例**：
- 当模型对某些区间的 $X$ 值过度估计，而对其他区间的 $X$ 值低估时，表明模型拟合不佳，可能是因为假设的线性关系并不成立。
- 展示了一个非线性模型的回归结果，发现残差存在明显模式，提示线性假设可能被违反。

**残差分析**：
- 观察残差与自变量之间的关系：如果残差图存在明显的模式（如某些区间残差上升或下降），则表明模型可能未能正确捕捉到数据的线性关系。

#### 假设 2：同方差性（Homoskedasticity）

**关键假设**：假设回归模型的残差方差对于所有观测值都是相同的，即假设满足同方差性（homoskedasticity）。这意味着对于所有的观测值，残差的方差应是恒定的，即：

$$ E(\epsilon_i^2) = \sigma^2_{\epsilon}, \quad i = 1, \dots, n $$

如果残差的方差在不同的观测值之间存在差异，则称为异方差性（heteroskedasticity）。

**重要概念**：
1. **同方差性**：假设回归模型的残差在所有观测点之间的方差是相同的，违反这一假设会导致估计结果偏误。
2. **异方差性**：当残差方差在不同观察值间不同，通常表示模型无法均匀拟合所有数据，可能是由于某些外部因素或数据特征所致。

**问题示例**：
- 假设我们正在分析短期利率（$Y$）与通货膨胀率（$X$）之间的关系。由于中央银行的政策不同，短期利率在某些年份可能会人为压低，这会导致回归模型在**不同时间段中拟合效果不同**，残差方差也会不同。
- 在这种情况下，模型的残差会在两个不同的时期（例如，正常利率阶段和低利率阶段）呈现出**显著不同的方差**，这表明存在异方差性。

**残差图分析**：
- **散点图**：通过绘制残差随年份的变化，可以观察到不同时间段内残差的方差差异。
- 对于正常利率阶段（Regime 1）和低利率阶段（Regime 2），残差的方差差异明显，Regime 1 的残差变动较小，而 Regime 2 的残差变动较大。

**解决方案**：
- 如果我们为每个时期（Regime 1 和 Regime 2）**分别估算回归线**，结果显示模型在两个时期的斜率明显不同，这表明需要分开拟合不同的回归模型。

#### 假设 3：独立性（Independence）

**关键假设**：假设观测值（$Y$ 和 $X$ 的配对）是相互独立的，即它们之间没有相关性。如果观测值之间存在相关性（例如自相关），则说明它们不是独立的，回归模型的残差也会存在相关性。假设残差在观测值之间是无关的，这对于正确估计回归参数的方差（如截距$b_0$ 和斜率$b_1$）非常重要，这些参数在假设检验中使用。

**重要概念**：
1. **独立性**：观测值之间不应存在任何形式的相关性（如自相关），否则残差也将不独立，可能影响模型的有效性和假设检验。
2. **自相关**：当残差在不同观测值之间有相关性时，称为自相关。自相关的存在通常表明模型没有捕捉到数据中的某些模式。

**解决方案**：
- 当残差显示出模式时，通常表明模型没有考虑到数据的某些特征，可能需要引入时间序列方法或调整模型以消除这种自相关。

#### 假设 4：正态性（Normality）

**关键假设**：假设回归模型的残差呈正态分布。这并不意味着自变量和因变量必须是正态分布的，而是指残差应符合正态分布。然而，在估计任何模型时，了解自变量和因变量的分布是良好的实践，因为这有助于识别异常值。任何一个变量中的异常值都可能显著影响拟合直线，导致估计的模型无法很好地拟合大多数其他观测值。

**正态性的重要性**：
1. **残差的正态分布**：如果残差符合正态分布，就能确保许多统计测试的有效性。例如，t检验和F检验都依赖于残差的正态性。
2. **异常值的影响**：如果自变量或因变量包含异常值，这些异常值可能会对回归模型的拟合产生不利影响，导致模型失真。

**大样本下的正态性**：
- 对于大样本，通常可以依赖中心极限定理（Central Limit Theorem），即使残差不是正态分布，回归统计量依然是有效的。渐近理论表明，在许多情况下，标准回归程序产生的检验统计量在样本量足够大时依然有效。

**实践**：
- 尽管大样本情况下正态性假设可以放宽，但在小样本或具体模型中，仍然建议检查残差是否符合正态分布。

